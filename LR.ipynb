{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Dataset\n",
    "Load the 'house_prices.csv' dataset using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('house_prices.csv')\n",
    "\n",
    "# Display the first 5 rows of the dataframe\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Data with Seaborn\n",
    "Create various graphs to visualize the data and its distributions using seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Importing numpy\n",
    "\n",
    "# Boxplot for each numeric column to identify outliers\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "for col in numeric_cols:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.boxplot(x=df[col])\n",
    "    plt.title('Boxplot - {}'.format(col))\n",
    "    plt.show()\n",
    "\n",
    "# Scatterplot for SalePrice against each numeric column\n",
    "for col in numeric_cols:\n",
    "    if col != 'SalePrice':\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.scatterplot(x=df[col], y=df['SalePrice'])\n",
    "        plt.title('SalePrice vs {}'.format(col))\n",
    "    plt.show()\n",
    "\n",
    "# Countplot for each categorical column\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "for col in categorical_cols:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.countplot(x=df[col])\n",
    "    plt.title('Countplot - {}'.format(col))\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show() \n",
    "\n",
    "# Violinplot for SalePrice against each categorical column\n",
    "for col in categorical_cols:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.violinplot(x=df[col], y=df['SalePrice'])\n",
    "    plt.title('SalePrice vs {}'.format(col))\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select Numeric and Categorical Attributes\n",
    "Select a numeric and a categorical attribute that have a relationship for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting a numeric and a categorical attribute for further analysis\n",
    "# For this example, let's select 'OverallQual' as the categorical attribute and 'SalePrice' as the numeric attribute\n",
    "# These attributes are selected based on the correlation matrix and the violin plots\n",
    "\n",
    "numeric_attribute = 'SalePrice'\n",
    "categorical_attribute = 'OverallQual'\n",
    "\n",
    "# Display the selected attributes\n",
    "print(\"Selected Numeric Attribute: \", numeric_attribute)\n",
    "print(\"Selected Categorical Attribute: \", categorical_attribute)\n",
    "\n",
    "# Plotting the relationship between the selected numeric and categorical attributes\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=df[categorical_attribute], y=df[numeric_attribute])\n",
    "plt.title('Relationship between {} and {}'.format(categorical_attribute, numeric_attribute))\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Model\n",
    "Build a Linear Regression model using the selected attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries for Linear Regression\n",
    "\n",
    "from %pip install scikit-learn\n",
    "sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Preparing the data for the Linear Regression model\n",
    "# Using the selected numeric attribute as the target variable and the selected categorical attribute as the predictor\n",
    "X = df[[categorical_attribute]]\n",
    "y = df[numeric_attribute]\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Creating the Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Training the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Printing the evaluation metrics\n",
    "print(\"Mean Squared Error: \", mse)\n",
    "print(\"R^2 Score: \", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Regressor\n",
    "Use a Decision Tree Regressor to explain how the Linear Regression model makes decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries for Decision Tree Regressor\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "\n",
    "# Creating the Decision Tree Regressor model\n",
    "tree_model = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# Training the model\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions\n",
    "y_pred_tree = tree_model.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "mse_tree = mean_squared_error(y_test, y_pred_tree)\n",
    "r2_tree = r2_score(y_test, y_pred_tree)\n",
    "\n",
    "# Printing the evaluation metrics\n",
    "print(\"Mean Squared Error (Decision Tree): \", mse_tree)\n",
    "print(\"R^2 Score (Decision Tree): \", r2_tree)\n",
    "\n",
    "# Plotting the Decision Tree\n",
    "plt.figure(figsize=(20,10))\n",
    "plot_tree(tree_model, filled=True, feature_names=[categorical_attribute])\n",
    "plt.title('Decision Tree')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Model\n",
    "Build a Logistic Regression model using the selected attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries for Logistic Regression\n",
    "\n",
    "from %pip install sklearn\n",
    "sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Preparing the data for the Logistic Regression model\n",
    "# Converting the numeric target variable into a binary variable\n",
    "# For this example, let's consider houses with a price above the median as 'expensive' (1) and the rest as 'not expensive' (0)\n",
    "y_binary = (y > y.median()).astype(int)\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train_binary, y_test_binary = train_test_split(X, y_binary, test_size=0.2, random_state=42)\n",
    "\n",
    "# Creating the Logistic Regression model\n",
    "logistic_model = LogisticRegression()\n",
    "\n",
    "# Training the model\n",
    "logistic_model.fit(X_train, y_train_binary)\n",
    "\n",
    "# Making predictions\n",
    "y_pred_binary = logistic_model.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "accuracy = accuracy_score(y_test_binary, y_pred_binary)\n",
    "conf_matrix = confusion_matrix(y_test_binary, y_pred_binary)\n",
    "\n",
    "# Printing the evaluation metrics\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Confusion Matrix: \\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier\n",
    "Use a Decision Tree Classifier to explain how the Logistic Regression model makes decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries for Decision Tree Classifier\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn import tree\n",
    "from IPython.display import Image  \n",
    "import %pip install pydotplus\n",
    "pydotplus\n",
    "\n",
    "# Preparing the data for the Decision Tree Classifier model\n",
    "# Using the binary target variable from the Logistic Regression model\n",
    "y_train_classifier = y_train_binary\n",
    "y_test_classifier = y_test_binary\n",
    "\n",
    "# Creating the Decision Tree Classifier model\n",
    "classifier_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Training the model\n",
    "classifier_model.fit(X_train, y_train_classifier)\n",
    "\n",
    "# Making predictions\n",
    "y_pred_classifier = classifier_model.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "accuracy_classifier = accuracy_score(y_test_classifier, y_pred_classifier)\n",
    "conf_matrix_classifier = confusion_matrix(y_test_classifier, y_pred_classifier)\n",
    "\n",
    "# Printing the evaluation metrics\n",
    "print(\"Accuracy (Decision Tree Classifier): \", accuracy_classifier)\n",
    "print(\"Confusion Matrix (Decision Tree Classifier): \\n\", conf_matrix_classifier)\n",
    "\n",
    "# Visualizing the Decision Tree\n",
    "dot_data = tree.export_graphviz(classifier_model, out_file=None, \n",
    "                                feature_names=[categorical_attribute],  \n",
    "                                class_names=['not expensive', 'expensive'])\n",
    "\n",
    "# Draw graph\n",
    "graph = pydotplus.graph_from_dot_data(dot_data)  \n",
    "\n",
    "# Show graph\n",
    "Image(graph.create_png())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La validación cruzada es una técnica utilizada para evaluar la eficacia de un modelo de aprendizaje automático. Existen varios métodos de validación cruzada, cada uno con sus propias ventajas y desventajas:\n",
    "\n",
    "1. **K-Fold Cross Validation**: En este método, el conjunto de datos se divide en 'k' subconjuntos. Uno de los subconjuntos se utiliza como conjunto de prueba y el resto como conjunto de entrenamiento. El proceso se repite 'k' veces, cada vez con un subconjunto diferente como conjunto de prueba. Este método es útil cuando se dispone de un tamaño de muestra grande.\n",
    "\n",
    "2. **Stratified K-Fold Cross Validation**: Este método es una variante de K-Fold que puede producir un sesgo y una varianza más bajos en casos en los que el conjunto de datos no está equilibrado. En Stratified K-Fold, se mantiene la proporción de cada clase objetivo en cada pliegue.\n",
    "\n",
    "3. **Shuffle Split**: Este método genera un número predefinido de conjuntos de entrenamiento y prueba independientes. Los conjuntos de prueba y entrenamiento se generan dividiendo aleatoriamente el conjunto de datos completo. Este método es útil cuando se quiere un control más directo sobre el número de iteraciones y el tamaño de los conjuntos de prueba y entrenamiento.\n",
    "\n",
    "Cada uno de estos métodos tiene sus propias ventajas y puede ser más útil en ciertos escenarios. La elección del método de validación cruzada depende en gran medida del conjunto de datos y del problema específico que se está tratando de resolver."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este notebook, hemos explorado diferentes métodos de validación cruzada y cómo pueden impactar en la eficacia de un modelo de aprendizaje automático. Hemos discutido las ventajas y desventajas de K-Fold, Stratified K-Fold y Shuffle Split. Cada método tiene sus propias fortalezas y puede ser más adecuado para ciertos escenarios. La elección del método de validación cruzada debe basarse en el conjunto de datos específico y el problema que se está tratando de resolver. En resumen, la validación cruzada es una herramienta esencial para evaluar la eficacia de un modelo y seleccionar el método de validación cruzada más adecuado puede mejorar significativamente el rendimiento del modelo."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
